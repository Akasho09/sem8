{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1770310979049,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "5111a66e"
   },
   "outputs": [],
   "source": [
    "sample_text_corpus = \"\"\"Mr. Smith went to U.S.A.\n",
    "He met Dr. Jane Doe there. She was a very intelligent person.\n",
    "This is a test sentence.\n",
    "This is a test sentence.\n",
    "The quick brown fox jumps over the lazy dog.\n",
    "A.I. advancements are significant. Etc., etc.\n",
    "The company's R&D department is working on new tech.\n",
    "We hope for success. We hope for success.\"\"\"\n",
    "\n",
    "with open(\"sampletext.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(sample_text_corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1770310979050,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "JxFrXz66qAMq"
   },
   "outputs": [],
   "source": [
    "with open(\"sampletext.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1770310979059,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "168a5f90",
    "outputId": "acbdda4e-9109-4627-c155-ebe8805c9ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Smith went to U.S.A.\n",
      "He met Dr. Jane Doe there. She was a very intelligent person.\n",
      "This is a test sentence.\n",
      "This is a test sentence.\n",
      "The quick brown fox jumps over the lazy dog.\n",
      "A.I. advancements are significant. Etc., etc.\n",
      "The company's R&D department is working on new tech.\n",
      "We hope for success. We hope for success.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1770310979066,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "38c0ead5",
    "outputId": "ab8e12c0-6da9-4483-b9a1-5db7adfa6fe9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m text_lower = text.lower()\n\u001b[32m      3\u001b[39m token_pattern = \u001b[33mr\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33m    (?:[a-z]\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.)\u001b[39m\u001b[33m{\u001b[39m\u001b[33m2,}        # abbreviations like u.s.a.\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m    | [a-z]+&[a-z]+                 # r&d\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m    | [a-z]+(?:\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[a-z]+)?   # normal words\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m words = \u001b[43mre\u001b[49m.findall(token_pattern, text_lower, re.VERBOSE)\n\u001b[32m     11\u001b[39m word_frequencies = Counter(words)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWord Tokenization and Frequencies:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "text_lower = text.lower()\n",
    "\n",
    "token_pattern = r\"\"\"\n",
    "    (?:[a-z]\\.){2,}        # abbreviations like u.s.a.\n",
    "    | [a-z]+&[a-z]+                 # r&d\n",
    "    | [a-z]+(?:'[a-z]+)?   # normal words\n",
    "\"\"\"\n",
    "\n",
    "words = re.findall(token_pattern, text_lower, re.VERBOSE)\n",
    "\n",
    "word_frequencies = Counter(words)\n",
    "\n",
    "print(\"Word Tokenization and Frequencies:\")\n",
    "for word, count in word_frequencies.most_common():\n",
    "    print(f\"'{word}': {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1770310979072,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "5ded0c86",
    "outputId": "b547fa30-a0bc-4df2-c268-669143c110bd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_frequencies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vocabulary_size = \u001b[38;5;28mlen\u001b[39m(\u001b[43mword_frequencies\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVocabulary Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocabulary_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'word_frequencies' is not defined"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(word_frequencies)\n",
    "\n",
    "print(f\"Vocabulary Size: {vocabulary_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770310979077,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "90cf519f",
    "outputId": "37f06340-6edb-4225-f469-dc6226135215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization and Count:\n",
      "Sentence 1: Mr. Smith went to U.S.A.\n",
      "He met Dr. Jane Doe there.\n",
      "Sentence 2: She was a very intelligent person.\n",
      "Sentence 3: This is a test sentence.\n",
      "Sentence 4: This is a test sentence.\n",
      "Sentence 5: The quick brown fox jumps over the lazy dog.\n",
      "Sentence 6: A.I. advancements are significant.\n",
      "Sentence 7: Etc., etc.\n",
      "Sentence 8: The company's R&D department is working on new tech.\n",
      "Sentence 9: We hope for success.\n",
      "Sentence 10: We hope for success.\n",
      "\n",
      "Total number of sentences: 10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence_pattern = re.compile(\n",
    "   r\"\"\"\n",
    "    (?<!\\b[A-Z][a-z]\\.)        # not titles like Mr., Dr.\n",
    "    (?<!\\b[A-Z]\\.)             # not single initial like A.\n",
    "    (?<!\\b[A-Z]\\.[A-Z]\\.)      # not A.I.\n",
    "    (?<!\\b[A-Z]\\.[A-Z]\\.[A-Z]\\.) # not U.S.A.\n",
    "    (?<=[.!?])                 # sentence-ending punctuation\n",
    "    \\s+(?=[A-Z])               # space + Capital letter\n",
    "    \"\"\",\n",
    "    re.VERBOSE\n",
    ")\n",
    "\n",
    "\n",
    "sentences = sentence_pattern.split(text)\n",
    "\n",
    "sentences = [s.strip()  for s in sentences if s.strip()]\n",
    "\n",
    "print(\"Sentence Tokenization and Count:\")\n",
    "for i, sentence in enumerate(sentences, start=1):\n",
    "    print(f\"Sentence {i}: {sentence}\")\n",
    "\n",
    "print(f\"\\nTotal number of sentences: {len(sentences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770310979083,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "a4afec2c",
    "outputId": "17d1143b-a50c-4711-f62a-b412f1400a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Sentences with IDs:\n",
      "ID 1: Mr. Smith went to U.S.A.\n",
      "He met Dr. Jane Doe there.\n",
      "ID 2: She was a very intelligent person.\n",
      "ID 3: This is a test sentence.\n",
      "ID 4: The quick brown fox jumps over the lazy dog.\n",
      "ID 5: A.I. advancements are significant.\n",
      "ID 6: Etc., etc.\n",
      "ID 7: The company's R&D department is working on new tech.\n",
      "ID 8: We hope for success.\n",
      "\n",
      "Total number of unique sentences: 8\n"
     ]
    }
   ],
   "source": [
    "unique_sentences_with_ids = []\n",
    "seen_sentences = set()\n",
    "sentence_id_counter = 1\n",
    "\n",
    "for sentence in sentences:\n",
    "    normalized_sentence = sentence.strip().lower()\n",
    "    if normalized_sentence not in seen_sentences:\n",
    "        seen_sentences.add(normalized_sentence)\n",
    "        unique_sentences_with_ids.append((sentence_id_counter, sentence))\n",
    "        sentence_id_counter += 1\n",
    "\n",
    "print(\"Unique Sentences with IDs:\")\n",
    "for sentence_id, sentence_text in unique_sentences_with_ids:\n",
    "    print(f\"ID {sentence_id}: {sentence_text}\")\n",
    "\n",
    "print(f\"\\nTotal number of unique sentences: {len(unique_sentences_with_ids)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNMxutjwtwBbYO7XeOe61jr",
   "mount_file_id": "1QC6LXKPY9oICI3K6kKXpnvKlHuzxj0rR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
