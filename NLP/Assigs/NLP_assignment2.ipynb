{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1770312525119,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "SqgnZNqW0l_f"
   },
   "outputs": [],
   "source": [
    "training_corpus = [\n",
    "    \"low\", \"lower\", \"lowest\",\n",
    "    \"new\", \"newer\", \"newest\",\n",
    "    \"wide\", \"wider\", \"widest\",\n",
    "    \"slow\", \"slower\", \"slowest\",\n",
    "    \"bright\", \"brighter\", \"brightest\",\n",
    "    \"smart\", \"smarter\", \"smartest\",\n",
    "    \"quick\", \"quicker\", \"quickest\",\n",
    "    \"cold\", \"colder\", \"coldest\",\n",
    "    \"strong\", \"stronger\", \"strongest\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh9ZXoXg0wlg"
   },
   "source": [
    "Each word is split into characters and marked with an end symbol \\</w>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770312525124,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "ccdXc_JZ0upF"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def build_vocab(corpus):\n",
    "    vocab = Counter()\n",
    "    for word in corpus:\n",
    "        vocab[\" \".join(list(word)) + \" </w>\"] += 1\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qvEppFp1EvS"
   },
   "source": [
    "Finds most frequent adjacent characters/subwords <br>\n",
    "These pairs are candidates for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1770312525142,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "-EPDM_Eq1DqG"
   },
   "outputs": [],
   "source": [
    "def get_pair_frequencies(vocab):\n",
    "    pairs = defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[(symbols[i], symbols[i+1])] += freq\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOk1wFbW1dur"
   },
   "source": [
    "Merge the Most Frequent Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1770312525968,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "oN5Rz1hG1cZ4"
   },
   "outputs": [],
   "source": [
    "def merge_pair(pair, vocab):\n",
    "    new_vocab = {}\n",
    "    bigram = \" \".join(pair)\n",
    "    merged = \"\".join(pair)\n",
    "\n",
    "    for word in vocab:\n",
    "        new_word = word.replace(bigram, merged)\n",
    "        new_vocab[new_word] = vocab[word]\n",
    "\n",
    "    return new_vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GDDO9VG10vX"
   },
   "source": [
    "Train the BPE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770312525972,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "wEvoboXt1y2t"
   },
   "outputs": [],
   "source": [
    "def train_bpe(corpus, num_merges):\n",
    "    vocab = build_vocab(corpus)\n",
    "    merges = []\n",
    "\n",
    "    for _ in range(num_merges):\n",
    "        pairs = get_pair_frequencies(vocab)\n",
    "        if not pairs:\n",
    "            break\n",
    "\n",
    "        best_pair = max(pairs, key=pairs.get)\n",
    "        merges.append(best_pair)\n",
    "        vocab = merge_pair(best_pair, vocab)\n",
    "\n",
    "    return merges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4EQ4CNC19ZF"
   },
   "source": [
    "train with multiple merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1770312525980,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "KeIJjAi418Eq",
    "outputId": "bc4ac94b-620f-4c31-9848-3fa9e7597551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned BPE merges:\n",
      "('s', 't')\n",
      "('e', 'r')\n",
      "('er', '</w>')\n",
      "('e', 'st')\n",
      "('est', '</w>')\n",
      "('l', 'o')\n",
      "('lo', 'w')\n",
      "('n', 'e')\n",
      "('ne', 'w')\n",
      "('w', 'i')\n",
      "('wi', 'd')\n",
      "('s', 'low')\n",
      "('b', 'r')\n",
      "('br', 'i')\n",
      "('bri', 'g')\n",
      "('brig', 'h')\n",
      "('brigh', 't')\n",
      "('s', 'm')\n",
      "('sm', 'a')\n",
      "('sma', 'r')\n",
      "('smar', 't')\n",
      "('q', 'u')\n",
      "('qu', 'i')\n",
      "('qui', 'c')\n",
      "('quic', 'k')\n",
      "('c', 'o')\n",
      "('co', 'l')\n",
      "('col', 'd')\n",
      "('st', 'r')\n",
      "('str', 'o')\n"
     ]
    }
   ],
   "source": [
    "bpe_merges = train_bpe(training_corpus, num_merges=30)\n",
    "\n",
    "print(\"Learned BPE merges:\")\n",
    "for m in bpe_merges:\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1770312525983,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "3P-kXqd52HFp"
   },
   "outputs": [],
   "source": [
    "test_corpus = [\n",
    "    \"smartest\",\n",
    "    \"quickest\",\n",
    "    \"slowest\",\n",
    "    \"newer\",\n",
    "    \"stronger\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FUmA1ii2L1C"
   },
   "source": [
    "Apply BPE Tokenization on Test Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1770312526569,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "uMYs-eYG2LD8"
   },
   "outputs": [],
   "source": [
    "def bpe_tokenize(word, merges):\n",
    "    tokens = list(word) + [\"</w>\"]\n",
    "\n",
    "    for merge in merges:\n",
    "        i = 0\n",
    "        while i < len(tokens) - 1:\n",
    "            if tokens[i] == merge[0] and tokens[i+1] == merge[1]:\n",
    "                tokens[i:i+2] = [\"\".join(merge)]\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc0oyk5M2Sjo"
   },
   "source": [
    "Tokenize and Display Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1770312526578,
     "user": {
      "displayName": "Faisal Wani",
      "userId": "06464638018335848670"
     },
     "user_tz": -330
    },
    "id": "wJrm18AI2PEd",
    "outputId": "c7cd82fa-4bc9-4415-8563-ce1a0d75972a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized Test Corpus:\n",
      "smartest → ['smart', 'est</w>']\n",
      "quickest → ['quick', 'est</w>']\n",
      "slowest → ['slow', 'est</w>']\n",
      "newer → ['new', 'er</w>']\n",
      "stronger → ['stro', 'n', 'g', 'er</w>']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTokenized Test Corpus:\")\n",
    "for word in test_corpus:\n",
    "    print(word, \"→\", bpe_tokenize(word, bpe_merges))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJbZlpECPTUVc16w5y508A",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
